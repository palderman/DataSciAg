---
title: "Programming with Data - Defining Functions"
author: |
  | Data Science for Agriculture and Natural Resources
  | PLNT 5413 - Fall `r format(Sys.Date(),'%Y')`
output: pdf_document
link-citations: true
urlcolor: blue
margin: 1in
fontsize: 12pt
geometry: "left=1in,right=1in,top=1in,bottom=1.25in"
header-includes:
  - \usepackage{titling}
  - \usepackage{lastpage}
  - \usepackage{fancyhdr}
  - \newcommand{\aspace}[1]{\vspace{#1\baselineskip}}
  - \renewcommand{\headrulewidth}{0pt}
  - \fancypagestyle{plain}{ \fancyhf{} \fancyfoot[C]{\aspace{2}Page     \thepage~of~\pageref{LastPage}} }
  - \pagestyle{fancy}
  - \fancyhf{}
  - \fancyfoot[C]{\small \thetitle \\ Data Science for Agriculture and Natural Resources\\PLNT 5413 - Fall `r format(Sys.Date(),'%Y')`\\ Page \thepage~of~\pageref{LastPage}}
---

```{r setup,echo=FALSE}
knitr::opts_chunk$set(echo=FALSE,include=TRUE)
```

```{r program_assignment_code, echo=FALSE, include=FALSE}
library(tidyverse)

# Generate separate files for each forest division
tree_raw <- read_tsv('Macroplot_data_Rev.txt')
site_data <- read_tsv('Site_variables.txt')
joined <- site_data %>%
  select(PlotID,ForestDiv) %>%
  right_join(tree_raw, by='PlotID')

dir.create('data')
for(fd in unique(joined$ForestDiv)){
  filter(joined,ForestDiv==fd) %>%
    write_tsv(.,paste0('data/',fd,'_tree_data.txt'))
  filter(site_data,ForestDiv==fd) %>%
    write_tsv(.,paste0('data/',fd,'_site_data.txt'))
}

system("cd data; zip ../ForestInventory.zip *.txt")

```

In the *Wrangling Data* module, we wrangled a dataset sampled from southern India. In that case, the dataset had already been combined and curated fairly well before we started working with it. When we are working with "real" datasets (particularly multi-location datasets), we often start with multiple files and have to do some serious work importing and combining the data to put it in a form we can use. Using programming skills related to workflows (pipelines), functions, and iteration can greatly facilitate that process. For this module, we will focus on that context for practicing proper application of these skills.

Download the attached zip archive file. Create a new subdirectory within your assignment directory called `data` and extract the zip archive into that directory. You'll notice that the data are organized by forest division with one file of tree data and one file of site data for each forest division. Your overall goal for this assignment will be to combine these individual files into a unified dataset prepared for analysis. The general approach we will use is to process the data by forest division and then combine the results into a final dataset. Don't forget to load package dependencies and add comments to the code to mark each problem and explain each step of the workflow.

1. The first stage in this process is to get a list of forest divisions that we can iterate over. Write a function called `list_forest_divisions()` that:
    * Takes a data directory path as an argument
    * Finds files in that directory
    * Strips off any extra parts (e.g. file path, extension, etc.) of the file names
    * Returns a list that includes each forest division name exactly once

        *Hint: The `list.files()` function, the [Strings](http://r4ds.had.co.nz/strings.html) chapter, and the `stringr` package will all be useful for this one.*
        
```{r problem_1_code}
# Problem 1
list_forest_divisions <- function(path){

  for_div_list <- list.files(path = path) %>% # list all files in the path directory
    str_replace_all('(.*/)|(_.*)','') %>% # Strip off any leading directories and trailing file extenstions including _tree_data or _site_data labels
    unique() # Remove duplicate entries in resulting list
  
  return(for_div_list)
}
```

```{r problem_1_output,echo=FALSE,include=TRUE}
for_divs <- list_forest_divisions('data')
for_divs
```

2. Now that we have a list of forest divisions, we need to be able to read and process the data within a given forest division. Write a function called `read_forest_division()` that:
    * Takes a data directory path and a forest division name as arguments
    * Converts the path and forest division name into file path and names for tree data files
    * Reads tree data into a tibble and marks '0' tree girth observations as missing (i.e.`NA`)
    * Returns the resulting tibble

        *Hint: Use `?read_tsv` to see an explanation of the arguments and some examples*
        
```{r problem_2_code}
# Problem 2
read_forest_division <- function(directory,for_div){

  tree_data <- paste0(directory,'/',for_div,'_tree_data.txt') %>% # Combine directory path and forest division to create tree data file name
    read_tsv(na = "0",                                  # Read tree data setting "0" observations to NA
             col_types = cols(PlotID = col_character(), # Specifying column types
                              SpCode = col_character(),
                              TreeGirth1 = col_double(),
                              TreeGirth2 = col_double(),
                              TreeGirth3 = col_double(),
                              TreeGirth4 = col_double(),
                              TreeGirth5 = col_double()))
  
  return(tree_data)   # Return combined data
}
```

```{r problem_2_output,echo=FALSE,include=TRUE}
cat(paste0('Example output for ',for_divs[1],'\n'))
for_div_1 <- read_forest_division('data',for_divs[1])
for_div_1
```
